{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1624550149291
    },
    "id": "kzqe7P92P79J",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1624550150031
    },
    "id": "6-uHEVilQHG0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624550986596
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "reinforcement_indexes = [136, 187, 246, 332, 405, 457, 522, 524, 548, 582, 637, 813, 819, 826, 827, 868, 1031, 1168, 1194, 1216, 1223, 1233, 1242, 1246, 1276, 1353, 1358, 1367, 1526, 1576, 1653, 1700, 1729, 1737, 1770, 1790, 1836, 1846, 1913, 1914, 1924, 1932, 1967, 2124, 2187, 2257, 2258, 2309, 2315, 2320, 2370, 2430, 2450, 2520, 2540, 2550, 2577, 2802, 2838, 2846, 2861, 2864, 2903, 2992, 3031, 3039, 3085, 3180, 3201, 3214, 3288, 3338, 3354, 3428, 3451, 3494, 3575, 3649, 3665, 3675, 3677, 3758, 3786, 3823, 3826, 3833, 3888, 3918, 3952, 3969, 4027, 4054, 4142, 4194, 4255, 4262, 4282]\n",
    "reinforcement_indexes = reinforcement_indexes * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gather": {
     "logged": 1624489305461
    },
    "id": "RsFhNGqAQzYx",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../progetto_2021_dataset/train_test_split_dict.json'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-4-941ceb393e2e>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mJSON_DATA\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mDATASET_DIR\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'train_test_split_dict.json'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m \u001B[0;32mwith\u001B[0m \u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mJSON_DATA\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mfp\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m     \u001B[0mdataset_json\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mjson\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfp\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../../progetto_2021_dataset/train_test_split_dict.json'"
     ]
    }
   ],
   "source": [
    "DATASET_DIR = \"../../progetto_2021_dataset/\"\n",
    "UNLABELED_DIR = \"../../unlabeled/\"\n",
    "CHECKPOINTS_DIR = \"../../checkpoints/\"\n",
    "\n",
    "JSON_DATA = os.path.join(DATASET_DIR, 'train_test_split_dict.json')\n",
    "\n",
    "with open(JSON_DATA) as fp:\n",
    "    dataset_json = json.load(fp)\n",
    "\n",
    "with open(\"../../unlabeled/unlabeled1_keys.json\", \"r\") as fd:\n",
    "    unlabeled_dirs = json.loads(json.load(fd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1624489306096
    },
    "id": "IE77x2rsQr7q",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CustomVGG(nn.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "    super(CustomVGG, self).__init__()\n",
    "\n",
    "    self.vgg = models.vgg16(pretrained=True, progress=False)\n",
    "    for param in self.vgg.features.parameters():\n",
    "      param.requires_grad = False\n",
    "\n",
    "    self.vgg.classifier.add_module(\"7\", nn.Linear(1000, 85)) \n",
    "\n",
    "  def forward(self, data):\n",
    "    return self.vgg(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1624489306933
    },
    "id": "emG-TYl0Qu3a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Augmenter(object):\n",
    "    def __init__(self, to_generate=30):\n",
    "        self.to_generate = to_generate\n",
    "        self.transformation = transforms.RandomChoice([\n",
    "                                transforms.ColorJitter(brightness=1, contrast=1, saturation=0.5),\n",
    "                                transforms.RandomRotation((10,180)),\n",
    "                                transforms.RandomAffine(0, translate=(0.2, 0.2))\n",
    "        ])\n",
    "\n",
    "    def __call__(self, images):\n",
    "        output = torch.zeros((self.to_generate, 3, 224, 224), dtype=torch.float32).to(device)\n",
    "        output[: images.shape[0]] = images\n",
    "        added_images = images.shape[0]\n",
    "        while added_images < self.to_generate:\n",
    "            rand_index = random.randint(0, images.shape[0] -1)\n",
    "            img = images[rand_index].clone()\n",
    "            output[added_images] = self.transformation(img)\n",
    "            added_images += 1\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1624489307583
    },
    "id": "w1oSJWqBRMna",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Dispatcher(object):\n",
    "    def __init__(self, device=\"cpu\", criterion=nn.BCEWithLogitsLoss(), largest=False, k=30):\n",
    "        super(Dispatcher, self).__init__()\n",
    "        self.criterion = criterion\n",
    "        self.largest = largest\n",
    "        self.k = k\n",
    "        \n",
    "        self.vgg = CustomVGG().to(device)\n",
    "        self.vgg.load_state_dict(torch.load(\"../../checkpoints/weighted_custom_vgg_10e.pth\"))\n",
    "        \n",
    "        self.augmenter = Augmenter(k)\n",
    "\n",
    "    def __call__(self, images, labels=None): #images = imm di un particolare trailer\n",
    "        len_ = images.shape[0]\n",
    "\n",
    "        if len_ > self.k:\n",
    "            return self.select_data(images, labels)\n",
    "        else:\n",
    "            return self.augmenter(images)\n",
    "\n",
    "\n",
    "    def select_data(self, images, labels):\n",
    "        y_scores = self.vgg(images)\n",
    "        if labels == None:\n",
    "            top_k_indexes = torch.randint(images.shape[0], (self.k,))\n",
    "        else:\n",
    "            top_k_indexes = self.select_top_k(y_scores, labels[0])\n",
    "        return images[top_k_indexes]\n",
    "\n",
    "\n",
    "    def select_top_k(self, y_preds, y_true):\n",
    "        n_items = y_preds.shape[0]\n",
    "        scores = torch.zeros(n_items)\n",
    "        for i in range(n_items):\n",
    "            scores[i] = self.criterion(y_preds[i], y_true)\n",
    "        top_k_indexes = torch.topk(scores, self.k, largest=self.largest)[1]\n",
    "        return top_k_indexes.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1624489308167
    },
    "id": "-8d0tdCISRQm",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CustomResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomResNet, self).__init__()\n",
    "\n",
    "        resnet = models.resnet34(pretrained=True, progress=False) \n",
    "        \n",
    "        layers = []\n",
    "     \n",
    "        layers.append(resnet.conv1)\n",
    "        layers.append(resnet.bn1)\n",
    "        layers.append(resnet.relu)\n",
    "        layers.append(resnet.maxpool)\n",
    "        layers.append(resnet.layer1)\n",
    "        layers.append(resnet.layer2)\n",
    "        layers.append(resnet.layer3)\n",
    "        layers.append(resnet.layer4)\n",
    "\n",
    "        self.feature_extraction = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, samples):\n",
    "        return self.feature_extraction(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1624489311356
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class BaggingSummarization(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaggingSummarization, self).__init__()\n",
    "\n",
    "        self.pooling = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "\n",
    "\n",
    "    def forward(self, samples):\n",
    "        output = self.pooling(samples)\n",
    "        return output.view(-1, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1624489311947
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class BaggingClassifier(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(BaggingClassifier, self).__init__()\n",
    "\n",
    "        self.summarization = BaggingSummarization()\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128, 85)\n",
    "        )\n",
    "\n",
    "    def forward(self, samples):\n",
    "        output_summaritazion = self.summarization(samples)\n",
    "        classifier_scores = self.classifier(output_summaritazion)\n",
    "        return torch.div(torch.sum(classifier_scores, axis=0), 30.0).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1624489312641
    },
    "id": "ve_xwmGVSMTg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim=1024):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "\n",
    "        self.encoder_end = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.BatchNorm1d(25088),\n",
    "            nn.Linear(25088, 2048),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(2048, latent_dim)\n",
    "        )    \n",
    "\n",
    "\n",
    "    def forward(self, samples):\n",
    "        return self.encoder_end(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1624489313259
    },
    "id": "0wiS9F2gS3uc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim=1024):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.linears = nn.Sequential(\n",
    "                                        nn.Linear(latent_dim, 2048),\n",
    "                                        nn.Dropout(0.4),\n",
    "                                        nn.Linear(2048, 25088)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, 3, stride=2, padding=1, output_padding=1), # 14\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1), # 28\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1), # 56\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1), # 112\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1), #224\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(16, 3, 3, padding=1), # 224\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, samples):\n",
    "        samples = self.linears(samples)\n",
    "        samples = samples.view(samples.shape[0], 512, 7, 7)\n",
    "        return self.decoder(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1624489314610
    },
    "id": "lJ50qP52Vl2_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Architecture(nn.Module):\n",
    "    \n",
    "    def __init__(self, device=\"cpu\", k=30):\n",
    "        super(Architecture, self).__init__()\n",
    "        \n",
    "        self.executor = ThreadPoolExecutor(max_workers=1)\n",
    "\n",
    "        self.dispatcher = Dispatcher(device=device, k=k)\n",
    "\n",
    "        self.feature_extraction = CustomResNet().to(device)\n",
    "\n",
    "        self.classifier = BaggingClassifier((k, 512, 7, 7)).to(device)\n",
    "\n",
    "        self.encoder = Encoder().to(device)\n",
    "\n",
    "        self.decoder = Decoder().to(device)\n",
    "\n",
    "\n",
    "    def forward(self, samples, labels):\n",
    "        samples = self.dispatcher(samples, labels)\n",
    "        \n",
    "        features = self.feature_extraction(samples)\n",
    "    \n",
    "        task = self.executor.submit(lambda: self.decoder(self.encoder(features)))\n",
    "    \n",
    "        output_classifier = self.classifier(features)\n",
    "       \n",
    "        output_decoder = task.result()\n",
    "        return samples, output_classifier, output_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1624550186998
    },
    "id": "9UGHAFEfbOCN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "architecture = Architecture(device, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624550189986
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels = set()\n",
    "\n",
    "for k in dataset_json.values():\n",
    "    for lable_list in k.values():\n",
    "        for v in lable_list:\n",
    "            labels.add(v)\n",
    "            \n",
    "label_idx = {v: i for i, v in enumerate(sorted(labels))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1624550191138
    },
    "id": "lErWq41Ng4CA",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SourceDataset(Dataset):\n",
    "\n",
    "    def __init__(self, path, dataset_dict, labels_int_dict, tranformations=None):\n",
    "      self.path = path\n",
    "      self.dataset_dict = dataset_dict\n",
    "      self.tranformations = transforms.ToTensor() if tranformations is None else tranformations\n",
    "      \n",
    "      self.to_skip = self.clean__()\n",
    "\n",
    "      to_keep = set(self.dataset_dict.keys()).difference(self.to_skip)\n",
    "\n",
    "      self.dirs_ = np.array(list(to_keep))\n",
    "      self.labels_dict_ = labels_int_dict\n",
    "\n",
    "      self.len = self.dirs_.shape[0]\n",
    "      self.labels_len = len(self.labels_dict_)\n",
    "\n",
    "\n",
    "    def clean__(self):\n",
    "      to_skip = []\n",
    "      for dir_name in self.dataset_dict.keys():\n",
    "        dir = self.path + \"/\" + dir_name\n",
    "        if os.path.isdir(dir):\n",
    "          if len(os.listdir(dir)) == 0:\n",
    "            to_skip.append(dir)\n",
    "      \n",
    "      return set(to_skip)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        name = self.dirs_[idx]\n",
    "        folder_pattern = os.path.join(self.path, name, '*.png')\n",
    "        images = io.imread_collection(folder_pattern)\n",
    "        data = torch.zeros(len(images), 3, 224, 224)\n",
    "        \n",
    "        for i, image in enumerate(images):\n",
    "          image = self.tranformations(Image.fromarray(image))\n",
    "          data[i] = image\n",
    "        labels = torch.zeros(self.labels_len, dtype=torch.float32)\n",
    "        for label in self.dataset_dict[name]:\n",
    "          labels[self.labels_dict_[label]] = 1\n",
    "        \n",
    "        return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624550194128
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MemorySourceDataset(Dataset):\n",
    "\n",
    "    def __init__(self, path, dataset_dict, labels_int_dict, tranformations=None):\n",
    "\n",
    "      self.path = path\n",
    "      self.dataset_dict = dataset_dict\n",
    "      self.tranformations = transforms.ToTensor() if tranformations is None else tranformations\n",
    "      \n",
    "      self.to_skip = self.clean__()\n",
    "\n",
    "      to_keep = set(self.dataset_dict.keys()).difference(self.to_skip)\n",
    "\n",
    "      self.dirs_ = np.array(list(to_keep))\n",
    "      self.labels_dict_ = labels_int_dict\n",
    "\n",
    "      self.len = self.dirs_.shape[0]\n",
    "      self.labels_len = len(self.labels_dict_)\n",
    "\n",
    "      self.data = self.memload__()\n",
    "\n",
    "\n",
    "    def memload__(self, jobs=6):\n",
    "        executor = ThreadPoolExecutor(max_workers=jobs)\n",
    "\n",
    "        jobs = []\n",
    "        \n",
    "        intervals = [(0, 715), (715, 1430), (1430, 2145), (2145, 2860), (2860, 3575), (3575, 4292)]\n",
    "        i = 0\n",
    "        for (start, end) in intervals:\n",
    "            print(f\"Job{i} submitted\")\n",
    "            jobs.append(executor.submit(self.range_load__, start, end))\n",
    "            i += 1\n",
    "        \n",
    "        data = []\n",
    "        for job in jobs:\n",
    "            data = data + job.result()\n",
    "\n",
    "        executor.shutdown()\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def range_load__(self, start, end):\n",
    "        data = []\n",
    "        for i in range(start, end):\n",
    "            data.append(self.dskload__(i))\n",
    "        return data\n",
    "            \n",
    "\n",
    "    def clean__(self):\n",
    "      to_skip = []\n",
    "      \n",
    "      for dir_name in self.dataset_dict.keys():\n",
    "        dir = self.path + \"/\" + dir_name\n",
    "        if os.path.isdir(dir):\n",
    "          if len(os.listdir(dir)) == 0:\n",
    "            to_skip.append(dir)\n",
    "      \n",
    "      return set(to_skip)\n",
    "\n",
    "    \n",
    "    def dskload__(self, idx):\n",
    "        name = self.dirs_[idx]\n",
    "        folder_pattern = os.path.join(self.path, name, '*.png')\n",
    "        images = io.imread_collection(folder_pattern)\n",
    "        data = torch.zeros(len(images), 3, 224, 224)\n",
    "        \n",
    "        for i, image in enumerate(images):\n",
    "          image = self.tranformations(Image.fromarray(image))\n",
    "          data[i] = image\n",
    "        labels = torch.zeros(self.labels_len, dtype=torch.float32)\n",
    "        for label in self.dataset_dict[name]:\n",
    "          labels[self.labels_dict_[label]] = 1\n",
    "        \n",
    "        return data, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624489341430
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class UnlabeledSourceDataset(Dataset):\n",
    "\n",
    "    def __init__(self, path, dir_names, transformations=None):\n",
    "      self.path = path\n",
    "      self.dir_names = dir_names\n",
    "      self.transformations = transforms.ToTensor() if transformations is None else transformations\n",
    "      \n",
    "      self.to_skip = self.clean__()\n",
    "\n",
    "      to_keep = set(self.dir_names).difference(self.to_skip)\n",
    "\n",
    "      self.dirs_ = np.array(list(to_keep))\n",
    "\n",
    "      self.len = self.dirs_.shape[0]\n",
    "\n",
    "\n",
    "    def clean__(self):\n",
    "      to_skip = []\n",
    "      labels = set()\n",
    "      for dir_name in self.dir_names:\n",
    "        dir = self.path + \"/\" + dir_name\n",
    "        if os.path.isdir(dir):\n",
    "          if len(os.listdir(dir)) == 0:\n",
    "            to_skip.append(dir)\n",
    "      \n",
    "      return set(to_skip)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        name = self.dirs_[idx]\n",
    "        folder_pattern = os.path.join(self.path, name, '*.png')\n",
    "        images = io.imread_collection(folder_pattern)\n",
    "        data = torch.zeros(len(images), 3, 224, 224)\n",
    "        \n",
    "        for i, image in enumerate(images):\n",
    "          image = self.transformations(Image.fromarray(image))\n",
    "          data[i] = image\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624491052097
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transformations = transforms.Compose([\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Resize((240, 240)),\n",
    "                                        transforms.CenterCrop((224, 224)),\n",
    "                                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "                                    ])\n",
    "train_dataset = MemorySourceDataset(DATASET_DIR, dataset_json[\"train\"], label_idx, transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624550200472
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = 0.75\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        targets = targets.type(torch.long)\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * ((1-pt) ** self.gamma) * BCE_loss\n",
    "        return F_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1624550204638
    },
    "id": "VD-ZmDZeHGTA",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.focal_loss = FocalLoss()\n",
    "        self.mse = nn.MSELoss()\n",
    "\n",
    "\n",
    "    def forward(self, y_pred, y_true, reconstructed, images):\n",
    "        focal_loss_score = self.focal_loss(y_pred, y_true)\n",
    "        mse_score = self.mse(reconstructed, images)\n",
    "        combined_loss = focal_loss_score + mse_score * 0.1\n",
    "        return combined_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624550205836
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "combined_loss = CombinedLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1624550210231
    },
    "id": "wYrmUJjdu7PH",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0005\n",
    "optimizer = torch.optim.Adam(architecture.parameters(), lr=learning_rate, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1624688130404
    },
    "id": "jUyhO5BtwrpF",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=1, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624550213413
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def save_train_checkpoint(epoch, model, optimizer, loss, name, root=CHECKPOINTS_DIR):\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            }, os.path.join(root, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624550216081
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_CHECKPOINT_NAME = \"arch_bce_reinforced_10e.pth\" #TODO\n",
    "MODEL_CHECKPOINT_NAME = \"arch_bce_reinforced_10e.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624550219020
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mask = torch.tensor([-1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1.,\n",
    "                    -1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
    "                    -1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
    "                    1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
    "                    1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
    "                    1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1.,\n",
    "                    1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624550220157
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trasformations_data_augmentation = transforms.RandomChoice([\n",
    "                                                                transforms.RandomRotation([-13,+13]),\n",
    "                                                                transforms.RandomHorizontalFlip(1),\n",
    "                                                                transforms.RandomVerticalFlip(1),\n",
    "                                                                transforms.RandomAffine(0, translate=(0.2, 0.2)),\n",
    "                                                                transforms.RandomAffine(degrees=0,scale=(0.5, 0.75))\n",
    "                                                            ]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624550221384
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def transform_images(samples, transformation=trasformations_data_augmentation):\n",
    "    result = torch.zeros_like(samples)\n",
    "    for i in range(samples.shape[0]):\n",
    "        result[i] = trasformations_data_augmentation(samples[i])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624551229820
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def reinforced_train(model, combined_loss, optimizer, loader, train_set, mask, epochs=5, threshold=2, device=\"cpu\"):\n",
    "    total_steps = len(loader)\n",
    "    loss = 0\n",
    "    model = model.to(device)\n",
    "    mask = mask.to(device)\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        random.shuffle(reinforcement_indexes)\n",
    "        queue_indexes = deque(reinforcement_indexes)\n",
    "        for batch_idx, (images, labels) in enumerate(loader):  \n",
    "            images = images[0].to(device)\n",
    "            labels = labels.to(device)\n",
    "            images, out_clf, out_dec = model(images, labels)\n",
    "            loss = combined_loss(out_clf, labels, out_dec, images)\n",
    "            optimizer.zero_grad() \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % 200 == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch, epochs, batch_idx, total_steps, loss.item()))\n",
    "            \n",
    "            if (batch_idx + 1) % 11 == 0 and len(queue_indexes) > 0: \n",
    "                augmented_images = transform_images(train_set[queue_indexes.pop()][0]).to(device)\n",
    "                augmented_images, out_clf, out_dec = model(augmented_images, labels)\n",
    "                loss = combined_loss(out_clf, labels, out_dec, augmented_images)\n",
    "                optimizer.zero_grad() \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        name = \"re_\" + TRAIN_CHECKPOINT_NAME\n",
    "        save_train_checkpoint(epoch, model, optimizer, loss, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624562960391
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def reinforced_train_with_unlabeled(model, combined_loss, optimizer, loader, unlabeled_loader, train_set, mask, epochs=5, threshold=2, step=3, top_k=10, device=\"cpu\"):\n",
    "    total_steps = len(loader)\n",
    "    loss = 0\n",
    "    model = model.to(device)\n",
    "    mask = mask.to(device)\n",
    "    unlabeled_iterator = iter(unlabeled_loader) \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        random.shuffle(reinforcement_indexes)\n",
    "        queue_indexes = deque(reinforcement_indexes)\n",
    "        for batch_idx, (images, labels) in enumerate(loader):  \n",
    "            images = images[0].to(device)\n",
    "            labels = labels.to(device)\n",
    "            images, out_clf, out_dec = model(images, labels)\n",
    "            loss = combined_loss(out_clf, labels, out_dec, images)\n",
    "            optimizer.zero_grad() \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % 200 == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch, epochs, batch_idx, total_steps, loss.item()))\n",
    "            \n",
    "            if (batch_idx + 1) % 11 == 0 and len(queue_indexes) > 0: \n",
    "                augmented_images = transform_images(train_set[queue_indexes.pop()][0]).to(device)\n",
    "                augmented_images, out_clf, out_dec = model(augmented_images, labels)\n",
    "                loss = combined_loss(out_clf, labels, out_dec, augmented_images)\n",
    "                optimizer.zero_grad() \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            if (batch_idx + 1) % step == 0:\n",
    "                images = next(unlabeled_iterator) \n",
    "                images = images[0].to(device) \n",
    "                images, out_clf, out_dec = model(images, None) \n",
    "                y_pred = torch.sigmoid(out_clf)\n",
    "                _, idx = torch.topk(y_pred, top_k, dim=1) \n",
    "                y_pred = torch.zeros_like(y_pred) \n",
    "                y_pred.scatter_(1, idx, 1) \n",
    "                loss = combined_loss(out_clf, y_pred, out_dec, images) \n",
    " \n",
    "                optimizer.zero_grad()  \n",
    "                loss.backward() \n",
    "                optimizer.step()\n",
    "                \n",
    "        name = \"re_\" + TRAIN_CHECKPOINT_NAME\n",
    "        save_train_checkpoint(epoch, model, optimizer, loss, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624551116849
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def save_model(model, name, root=CHECKPOINTS_DIR):\n",
    "  torch.save(model.state_dict(), \n",
    "             os.path.join(root, name))\n",
    "\n",
    "def load_model(name, root=CHECKPOINTS_DIR):\n",
    "  return torch.load(os.path.join(root, name))\n",
    "\n",
    "\n",
    "def exists_checkpoint(name, root=CHECKPOINTS_DIR):\n",
    "  return os.path.isfile(os.path.join(root, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1624550549994
    },
    "id": "vYCQ0Ye9u09j",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, combined_loss, optimizer, loader, epochs, device=\"cpu\"):\n",
    "    total_steps = len(loader)\n",
    "    loss = 0\n",
    "    model = model.to(device)\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        for batch_idx, (images, labels) in enumerate(loader):  \n",
    "            images = images[0].to(device)\n",
    "            labels = labels.to(device)\n",
    "            images, out_clf, out_dec = model(images, labels)\n",
    "            loss = combined_loss(out_clf, labels, out_dec, images)\n",
    "            optimizer.zero_grad() \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % 200 == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch, epochs, batch_idx, total_steps, loss.item()))\n",
    "        save_train_checkpoint(epoch, model, optimizer, loss, TRAIN_CHECKPOINT_NAME)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624550228084
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exists_checkpoint(MODEL_CHECKPOINT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "gather": {
     "logged": 1624550258376
    },
    "id": "Av87I3-UwzTV",
    "outputId": "2ac6b21b-be01-4a84-acba-361253224e53",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if not exists_checkpoint(MODEL_CHECKPOINT_NAME):\n",
    "    train(architecture, combined_loss, optimizer, train_loader, epochs=5, device=device)\n",
    "    save_model(architecture, MODEL_CHECKPOINT_NAME)\n",
    "    reinforced_train(architecture, combined_loss, optimizer, train_loader, 10, mask, threshold=3, times=3, device=device)\n",
    "    save_model(architecture, \"re_\" + MODEL_CHECKPOINT_NAME)\n",
    "else:\n",
    "    print(\"Checkpoint Found!\")\n",
    "    architecture.load_state_dict(load_model(MODEL_CHECKPOINT_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624560349030
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "reinforced_train(architecture, combined_loss, optimizer, train_loader, train_dataset, mask, epochs=3, threshold=2, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624532147574
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train(architecture, combined_loss, optimizer, train_loader, epochs=2, device=device)\n",
    "save_model(architecture, MODEL_CHECKPOINT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624546782675
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "reinforced_train(architecture, combined_loss, optimizer, train_loader, 5, mask, threshold=3, times=3, device=device)\n",
    "save_model(architecture, \"re_\" + MODEL_CHECKPOINT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624562836067
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "unlabeled_dataset = UnlabeledSourceDataset(UNLABELED_DIR, unlabeled_dirs, transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624688108910
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "unlabeled_loader = torch.utils.data.DataLoader(dataset=unlabeled_dataset, \n",
    "                                               batch_size=1,\n",
    "                                               shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624473619761
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def unlabeled_train(model, combined_loss, optimizer, labeled_loader, unlabeled_loader, epochs, top_k=10, device=\"cpu\"):\n",
    "    total_steps = len(labeled_loader) \n",
    "    loss = 0 \n",
    "    step = 4 \n",
    "    model = model.to(device) \n",
    "    unlabeled_iterator = iter(unlabeled_loader) \n",
    "    for epoch in range(1, epochs + 1): \n",
    "        for batch_idx, (images, labels) in enumerate(labeled_loader): \n",
    "            images = images[0].to(device) \n",
    "            labels = labels.to(device) \n",
    "            images, out_clf, out_dec = model(images, labels) \n",
    "            loss = combined_loss(out_clf, labels, out_dec, images) \n",
    "  \n",
    "            optimizer.zero_grad()  \n",
    "            loss.backward() \n",
    "            optimizer.step() \n",
    " \n",
    "            if (batch_idx + 1) % step == 0: \n",
    "                images = next(unlabeled_iterator) \n",
    "                images = images[0].to(device) \n",
    "                images, out_clf, out_dec = model(images, None) \n",
    "                y_pred = torch.sigmoid(out_clf)\n",
    "                _, idx = torch.topk(y_pred, top_k, dim=1) \n",
    "                y_pred = torch.zeros_like(y_pred) \n",
    "                y_pred.scatter_(1, idx, 1) \n",
    "                loss = combined_loss(out_clf, y_pred, out_dec, images) \n",
    " \n",
    "                optimizer.zero_grad()  \n",
    "                loss.backward() \n",
    "                optimizer.step() \n",
    " \n",
    "            if batch_idx % 200 == 0: \n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch, epochs, batch_idx, total_steps, loss.item())) \n",
    "        save_train_checkpoint(epoch, model, optimizer, loss, \"arch_focal_loss_ext_ul_train_11e.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624473571157
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "unlabeled_train(architecture, combined_loss, optimizer, train_loader, unlabeled_loader, epochs=2, top_k=10, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624547067108
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transformations = transforms.Compose([\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Resize((240, 240)),\n",
    "                                        transforms.CenterCrop((224, 224)),\n",
    "                                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "                                    ])\n",
    "                                    \n",
    "test_dataset = SourceDataset(DATASET_DIR, dataset_json[\"test\"], label_idx, transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624582619182
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "reinforced_train_with_unlabeled(architecture, combined_loss, optimizer, train_loader, unlabeled_loader, train_dataset, mask, epochs=3, threshold=2, step=3, top_k=10, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624582619650
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624582619848
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test(model, criterion, loader, labels_idx, topk=10, device=\"cpu\"):\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    predictions = []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(loader):\n",
    "            images = images[0].to(device)\n",
    "            labels = labels.to(device)\n",
    "            model = model.to(device)\n",
    "            images, out_clf, out_dec = model(images, labels)\n",
    "            \n",
    "            loss = criterion(out_clf, labels, out_dec, images)\n",
    "            y_pred = torch.sigmoid(out_clf)\n",
    "            _, idx = y_pred.topk(topk, dim=1)\n",
    "            y_pred = torch.zeros_like(y_pred)\n",
    "            y_pred.scatter_(1, idx, 1)\n",
    "            predictions.append(y_pred.cpu())\n",
    "            y_true.append(labels.cpu())\n",
    "            if batch_idx % 200 == 0:\n",
    "                print(batch_idx)\n",
    "        y_true, predictions = torch.cat(y_true, axis=0), torch.cat(predictions, axis=0)\n",
    "        report = classification_report(y_true, predictions, target_names=list(sorted(labels_idx.keys())))\n",
    "        print(report)\n",
    "        return y_true, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624584622110
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_true, predictions = test(architecture, combined_loss, test_loader, label_idx, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624587792609
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "reinforced_train(architecture, combined_loss, optimizer, train_loader, train_dataset, mask, epochs=1, threshold=2, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624600512439
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "reinforced_train_with_unlabeled(architecture, combined_loss, optimizer, train_loader, unlabeled_loader, train_dataset, mask, epochs=2, threshold=2, step=3, top_k=10, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624603504430
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "reinforced_train(architecture, combined_loss, optimizer, train_loader, train_dataset, mask, epochs=1, threshold=2, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624605538743
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_true, predictions = test(architecture, combined_loss, test_loader, label_idx, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624608158565
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "save_model(architecture, \"16_56_25.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624660890775
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "architecture = Architecture(device=device, k=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624660922620
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "architecture.load_state_dict(load_model(\"16_56_25.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624660937797
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(architecture.parameters(), lr=learning_rate, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624688587301
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=1, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624694383683
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "reinforced_train_with_unlabeled(architecture, combined_loss, optimizer, train_loader, unlabeled_loader, train_dataset, mask, epochs=1, threshold=2, step=3, top_k=10, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624694383976
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=1, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624699827941
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train(architecture, combined_loss, optimizer, train_loader, epochs=2, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624699828092
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=1, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624702805491
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "reinforced_train(architecture, combined_loss, optimizer, train_loader, train_dataset, mask, epochs=1, threshold=2, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1624704590007
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data. DataLoader(dataset=test_dataset, batch_size=1)\n",
    "y_true, predictions = test(architecture, combined_loss, test_loader, label_idx, device=device)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GlobalArchitecture.ipynb",
   "provenance": []
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}